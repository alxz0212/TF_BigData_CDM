# Tareas del Proyecto: TF Pipeline BigData con Infraestructura Docker

- [ ] Análisis de Requisitos <!-- id: 0 -->
  - [x] Crear estructura de carpetas <!-- id: 1 -->
  - [ ] Confirmar etapas del proyecto (basado en la imagen) <!-- id: 2 -->
- [ ] Etapa 1: Infraestructura (Docker) <!-- id: 3 -->
  - [ ] Definir `Dockerfile` para Spark y TensorFlow <!-- id: 4 -->
  - [ ] Definir `docker-compose.yml` (Jupyter, Spark, etc.) <!-- id: 5 -->
  - [ ] Verificar levantamiento de servicios <!-- id: 6 -->
- [ ] Etapa 2: Ingesta y Procesamiento de Datos <!-- id: 7 -->
  - [ ] Descarga/Carga del Dataset <!-- id: 8 -->
  - [ ] Limpieza y transformación con PySpark <!-- id: 9 -->
- [ ] Etapa 3: Pipeline de Machine Learning (TensorFlow) <!-- id: 10 -->
  - [ ] Preparación de datos para TF <!-- id: 11 -->
  - [ ] Entrenamiento del modelo <!-- id: 12 -->
  - [ ] Evaluación <!-- id: 13 -->
- [ ] Etapa 4: Documentación y Entrega <!-- id: 14 -->
  - [ ] Redactar `README.md` final <!-- id: 15 -->
  - [ ] Resumen de planes y justificación <!-- id: 16 -->
