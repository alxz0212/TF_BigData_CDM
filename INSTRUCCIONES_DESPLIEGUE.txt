================================================================================
GUÃA RÃPIDA DE DESPLIEGUE DESDE CERO (CHEAT SHEET)
Proyecto: Big Data & "Gran Juego" (Pipeline + ML + Dashboard)
================================================================================


PRERREQUISITOS:
1. Tener Docker Desktop instalado y corriendo.
2. Tener el cÃ³digo fuente descargado.
3. Abrir una terminal (PowerShell o CMD) en la carpeta raÃ­z del proyecto.

--------------------------------------------------------------------------------
PASO 0: PREPARACIÃ“N DE DATOS (IMPORTANTE) ðŸ“‚
--------------------------------------------------------------------------------
Antes de iniciar, necesitas el dataset "Quality of Government" (Time-Series).
1. Crea la carpeta donde irÃ¡n los datos raw.
2. Coloca el archivo 'qog_std_ts_jan26.csv' dentro.

Comando (PowerShell):
Comando (PowerShell):
> docker exec jupyter_lab python /home/jovyan/work/src/download_data.py

--------------------------------------------------------------------------------
PASO 1: LEVANTAR LA INFRAESTRUCTURA ðŸ³
--------------------------------------------------------------------------------
Enciende los servidores (Jupyter, Spark Master/Worker, Postgres).
El flag '-d' lo hace en segundo plano.

Comando:
Comando:
> docker-compose up -d --build

Espera a que se construya la imagen y arranque todo.
NOTA: La primera vez puede tardar entre 5 y 10 minutos (descarga de imÃ¡genes).
Las siguientes veces serÃ¡ casi instantÃ¡neo.

--->*Docker debe estar abierto antes de ejecutar cualquier comando*

--------------------------------------------------------------------------------
PASO 2: INSTALAR DEPENDENCIAS (AutomÃ¡tico) ðŸ“¦
--------------------------------------------------------------------------------
Las dependencias (Streamlit, PySpark, etc.) ahora se instalan automÃ¡ticamente 
al levantar el contenedor gracias al Dockerfile y requirements.txt.
Â¡Ya no necesitas ejecutar nada aquÃ­!


--------------------------------------------------------------------------------
PASO 3: EJECUTAR EL PIPELINE DE DATOS (ETL) âš™ï¸
--------------------------------------------------------------------------------
Procesa el CSV crudo y genera el archivo Parquet limpio.

Comando:
> docker exec jupyter_lab python /home/jovyan/work/src/pipeline.py

DeberÃ­as ver "Proceso ETL completado con Ã©xito".

--------------------------------------------------------------------------------
PASO 4: ENTRENAR MODELO Y GENERAR GRÃFICOS (SPARK) ðŸ“Š
--------------------------------------------------------------------------------
Calcula las correlaciones y entrena el Random Forest con PySpark.

Comando:
> docker exec jupyter_lab spark-submit /home/jovyan/work/src/analysis.py

Esto generarÃ¡ las imÃ¡genes .png en la carpeta notebooks/.

--------------------------------------------------------------------------------
PASO 5: EJECUTAR ANÃLISIS ECONOMÃ‰TRICO (HAUSMAN) ðŸ“‰
--------------------------------------------------------------------------------
Calcula Efectos Fijos vs Aleatorios para validar la hipÃ³tesis.

Comando:
> docker exec jupyter_lab python /home/jovyan/work/src/econometric_analysis.py

Genera reporte en notebooks/hausman_results.txt.

--------------------------------------------------------------------------------
PASO 6: LANZAR LA "SUPER WEB" (DASHBOARD) ðŸš€
--------------------------------------------------------------------------------
Inicia el servidor de Streamlit en segundo plano.

Comando:
> docker exec -d jupyter_lab streamlit run /home/jovyan/work/src/app_streamlit.py

--------------------------------------------------------------------------------
ACCESOS ðŸŒ
--------------------------------------------------------------------------------

ðŸ”¹ DASHBOARD (Streamlit):   http://localhost:8501
   (AquÃ­ estÃ¡ tu web interactiva con el Bot IA)

ðŸ”¹ JUPYTER LAB:             http://localhost:8888
   (ContraseÃ±a: bigdata2024 - Para ver el cÃ³digo o notebooks)

ðŸ”¹ SPARK MASTER:            http://localhost:8081
   (Para ver el estado del cluster)

ðŸ”¹ SPARK JOB UI:            http://localhost:4040
   (âš ï¸ OJO: Solo funciona **DURANTE** la ejecuciÃ³n del script. Al terminar, se cierra sola)

--------------------------------------------------------------------------------
CÃ“MO APAGAR TODO ðŸ›‘
--------------------------------------------------------------------------------
Cuando termines, elimina todo para limpiar tu mÃ¡quina.

Comando:
> docker-compose down
================================================================================
CÃ“MO ACTUALIZAR EN GITHUB ðŸ™
--------------------------------------------------------------------------------
Si haces cambios en el codigo y quieres subirlos a tu repositorio:

1.  Verificar estado de archivos modificados:
    > git status

2.  Agregar todos los cambios al area de preparacion (stage):
    > git add .

3.  Guardar los cambios con un mensaje descriptivo:
    > git commit -m "Mensaje explicando tus cambios"

4.  Subir los cambios a GitHub:
    > git push origin main

5.  (Opcional) Si hay cambios en el repositorio remoto que no tienes localmente:
    > git pull origin main

================================================================================
TROUBLESHOOTING / EXTRAS ðŸ› ï¸
--------------------------------------------------------------------------------

Â¿El Dashboard no se actualiza o se queda "pegado"?
A veces Streamlit no detecta cambios en el cÃ³digo. Para reiniciarlo "a la fuerza":

1. Mata el proceso actual:
> docker exec jupyter_lab pkill -f streamlit

2. InÃ­cialo de nuevo en segundo plano:
> docker exec -d jupyter_lab streamlit run /home/jovyan/work/src/app_streamlit.py

Â¿Error: "Ports are not available" o fallo de puerto?
Esto pasa si el puerto (8080, 8081, etc.) estÃ¡ ocupado por otro programa en tu PC.

SoluciÃ³n:
1. Abre el archivo `docker-compose.yml`.
2. Busca los `ports` del servicio que falla.
3. Cambia el nÃºmero de la IZQUIERDA (el de tu PC). 
   Ejemplo: Cambiar "8081:8080" a "8085:8080".
4. Vuelve a ejecutar: `docker-compose up -d`

================================================================================
--------------------------------------------------------------------------------
EJECUCIÃ“N RECURRENTE (SEGUNDA VEZ EN ADELANTE) ðŸ”„
--------------------------------------------------------------------------------
Si ya realizaste la instalaciÃ³n inicial y solo quieres volver a arrancar el proyecto:

1.  **Â¿DOCKER DESKTOP ABIERTO?**: SÃ. Es obligatorio que el programa "Docker Desktop" estÃ© abierto y funcionando antes de tirar cualquier comando.

2.  En tu terminal (carpeta del proyecto), ejecuta SOLO estos comandos:
    
    a) Levantar servicios:
       > docker-compose up -d

    b) (Opcional) Si quieres regenerar datos/modelos (si cambiaste algo):
       > docker exec jupyter_lab python /home/jovyan/work/src/pipeline.py
       > docker exec jupyter_lab spark-submit /home/jovyan/work/src/analysis.py
       > docker exec jupyter_lab python /home/jovyan/work/src/econometric_analysis.py

    c) Lanzar la Web (Dashboard):
       > docker exec -d jupyter_lab streamlit run /home/jovyan/work/src/app_streamlit.py

    d) Ir a: http://localhost:8501