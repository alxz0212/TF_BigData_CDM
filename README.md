# ğŸ“¡ AnÃ¡lisis Computacional de GeopolÃ­tica: El "Gran Juego" Post-SoviÃ©tico

> **Un enfoque de Big Data para entender la economÃ­a y seguridad en Asia Central.**

<div align="center">
    <img src="capturas/profile.jpg" alt="Daniel Alexis Mendoza Corne" width="150" style="border-radius: 50%;"/>
    <h3>ğŸ‘¤ Daniel Alexis Mendoza Corne</h3>
    <p>
        <b>Carrera:</b> IngenierÃ­a InformÃ¡tica y de Sistemas  <br> 
        <b>Nacionalidad:</b> Peruana ğŸ‡µğŸ‡ª <br>
        <a href="https://www.linkedin.com/in/alexismendoza12/">
            <img src="https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white" alt="LinkedIn"/>
        </a>
    </p>
</div>

---

## ğŸ“Œ Resumen Ejecutivo

Este proyecto aplica tÃ©cnicas de **Big Data** e **IngenierÃ­a de Software** para resolver una pregunta fundamental de las Ciencias PolÃ­ticas:

> _"Â¿Son los factores de 'Poder Duro' (Gasto Militar) o de 'Poder Blando' (Democracia, Control de CorrupciÃ³n) los que determinan el desarrollo econÃ³mico en la periferia post-soviÃ©tica?"_

A travÃ©s de un pipeline automatizado, se procesaron dÃ©cadas de datos histÃ³ricos de paÃ­ses clave del **"Gran Juego"** (AfganistÃ¡n, Mongolia, CÃ¡ucaso) para modelar matemÃ¡ticamente sus trayectorias de desarrollo.

### ğŸ› ï¸ Tech Stack
![Python](https://img.shields.io/badge/Python-3.9+-3776AB?style=flat-square&logo=python&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-Container-2496ED?style=flat-square&logo=docker&logoColor=white)
![Spark](https://img.shields.io/badge/Apache_Spark-Big_Data-E25A1C?style=flat-square&logo=apachespark&logoColor=white)
![Machine Learning](https://img.shields.io/badge/Machine_Learning-Random_Forest-orange?style=flat-square)
![Econometrics](https://img.shields.io/badge/Econometrics-Hausman_Test-green?style=flat-square)
![Streamlit](https://img.shields.io/badge/Frontend-Streamlit-FF4B4B?style=flat-square&logo=streamlit&logoColor=white)

---

## ğŸ—ï¸ Arquitectura del Sistema

El proyecto implementa un flujo de datos moderno y contenerizado:

```mermaid
graph TD
    %% Estilos
    classDef source fill:#f9f,stroke:#333,stroke-width:2px;
    classDef script fill:#bbf,stroke:#333,stroke-width:2px,color:black;
    classDef data fill:#dfd,stroke:#333,stroke-width:2px,color:black;
    classDef output fill:#fd9,stroke:#333,stroke-width:2px,color:black,stroke-dasharray: 5 5;

    subgraph INGESTA ["ğŸ“¡ Ingesta de Datos"]
        A[â˜ï¸ Internet / Repo QoG]:::source
        Script1{{ğŸ download_data.py}}:::script
    end

    subgraph PROCESAMIENTO ["âš™ï¸ Procesamiento & AnÃ¡lisis"]
        Script2{{âš¡ pipeline.py}}:::script
        Script3{{ğŸ§  analysis.py}}:::script
        Script5{{ğŸ“‰ econometric_analysis.py}}:::script
    end

    subgraph ALMACENAMIENTO ["ğŸ’¾ Almacenamiento"]
        B[(ğŸ“„ Raw CSV)]:::data
        C[(ğŸ“¦ Clean Parquet)]:::data
    end

    subgraph VISUALIZACION ["ğŸ“Š Consumo & UI"]
        Script4{{ğŸš€ app_streamlit.py}}:::script
        D[ğŸ“ˆ GrÃ¡ficos EstÃ¡ticos .png]:::output
        E[ğŸ–¥ï¸ Dashboard Interactivo]:::output
        F[ğŸ“„ Reporte Hausman .txt]:::output
    end

    %% Relaciones
    A --> Script1
    Script1 --> B
    B --> Script2
    Script2 --> C
    C --> Script3
    C --> Script4
    C --> Script5
    Script3 --> D
    Script4 --> E
    Script5 --> F
```

- **Infraestructura:** Docker Compose orquestando JupyterLab, Spark Master/Worker.
- **ETL:** PySpark para limpieza y transformaciÃ³n (`.parquet`).
- **AnalÃ­tica:**
    - **Machine Learning:** Random Forest (Spark MLlib) para Feature Importance.
    - **EconometrÃ­a:** Modelos de Datos de Panel (Fixed Effects vs Random Effects) y Test de Hausman.
- **Frontend:** Dashboard interactivo en Streamlit para exploraciÃ³n de datos.

---

## ğŸ” Hallazgos Principales

### 1. Inteligencia Artificial (Random Forest)
El modelo identificÃ³ que, descontando la salud bÃ¡sica (`Esperanza de Vida`), los factores de **Seguridad y Estabilidad del RÃ©gimen** tienen un peso predictivo superior a la mera democratizaciÃ³n.

### 2. ValidaciÃ³n EconomÃ©trica (Test de Hausman)
Se aplicÃ³ un **Test de Hausman** comparando modelos de Efectos Fijos vs Aleatorios.
- **Resultado:** Se prefiriÃ³ el modelo de **Efectos Fijos** ($P < 0.05$).
- **InterpretaciÃ³n:** Las caracterÃ­sticas Ãºnicas e invariables de cada paÃ­s ("El estilo uzbeko", "La geografÃ­a afgana") son determinantes estructurales del Ã©xito o fracaso econÃ³mico, confirmando la hipÃ³tesis de heterogeneidad regional.

---

## ğŸš€ Instrucciones de Despliegue

```bash
# 1. Levantar la infraestructura
docker compose up -d

# 2. Descargar e Ingestar Datos
docker exec jupyter_lab python /home/jovyan/work/src/download_data.py

# 3. Ejecutar Pipeline ETL (Raw -> Parquet)
docker exec jupyter_lab python /home/jovyan/work/src/pipeline.py

# 4. Entrenar Modelo de Machine Learning (Spark)
docker exec jupyter_lab spark-submit /home/jovyan/work/src/analysis.py

# 5. Ejecutar AnÃ¡lisis EconomÃ©trico (Hausman)
docker exec jupyter_lab python /home/jovyan/work/src/econometric_analysis.py

# 6. Lanzar Dashboard Web (http://localhost:8501)
docker exec -d jupyter_lab streamlit run /home/jovyan/work/src/app_streamlit.py
```

---

## ğŸ“‚ Estructura del Repositorio

```text
â”œâ”€â”€ 01_README.md                # Portada del proyecto (Este archivo)
â”œâ”€â”€ 02_INFRAESTRUCTURA.md       # DocumentaciÃ³n tÃ©cnica de Docker
â”œâ”€â”€ 03_RESULTADOS.md            # Informe detallado de hallazgos
â”œâ”€â”€ 04_REFLEXION_IA.md          # BitÃ¡cora de co-creaciÃ³n con IA
â”œâ”€â”€ 05_EXPLICACION_CODIGO.md    # CatÃ¡logo de scripts
â”œâ”€â”€ 06_RESPUESTAS.md            # Preguntas de defensa
â”œâ”€â”€ docker-compose.yml          # OrquestaciÃ³n
â”œâ”€â”€ src/                        # CÃ³digo Fuente Python
â”‚   â”œâ”€â”€ pipeline.py             # LÃ³gica ETL Big Data
â”‚   â”œâ”€â”€ analysis.py             # ML Engine
â”‚   â”œâ”€â”€ econometric_analysis.py # Stats Engine
â”‚   â””â”€â”€ app_streamlit.py        # Web App
â””â”€â”€ data/                       # Lakehouse (Raw + Processed)
```
